\section{Research Experiences}
\cventry{\footnotesize July 2015 - September 2015}{Information Initiative @ Duke (iiD), }{Duke University. }{}{Advised by Prof. \larrycarin .}{Worked on conditional factored deep generative models using recent Neural Variational Inference methods, which allows for semi-supervised deep learning and sequence generation with side information. \textbf{Our work is submitted to \textit{the 19th International Conference on Artificial Intelligence and Statistics}.}}{}

\cventry{\footnotesize November 2014 - June 2015}{ Statistical AI \& Learning (TSAIL) Group, }{Tsinghua University. }{}{ Advised by Prof. \junzhu .}{Explored stochastic variational methods for link prediction problems. Proposed an efficient method that would train on a network with over 3 million nodes, a significant improvement over original methods. \textbf{Our work is submitted to \textit{the IEEE Transactions on Pattern Recognition and Machine Intelligence}. }}{}

\cventry{\footnotesize July 2014 - October 2014}{Visual Computing Group, }{Microsoft Research Asia. }{}{Advised by \href{http://research.microsoft.com/en-us/um/people/jingdw/}{\color{nblue} Jingdong Wang}.}{Worked on classification and detection algorithms using deep learning methods; studied and modified Caffe, and open-source deep learning framework in C++ and CUDA; implemented a convolutional neural network for multiple label image annotation which achieved state-of-the-art precision results.}{}

\cventry{\footnotesize October 2013 - June 2014}{TSAIL, }{Tsinghua University. }{}{Advised by Prof \junzhu .}{ Implemented a Gibbs sampling benchmark algorithm for \href{http://papers.nips.cc/paper/4981-scalable-inference-for-logistic-normal-topic-models.pdf}{\color{nblue} Scalable Inference for Logistic Normal Topic Models} (accepted by NIPS 2013).}{}